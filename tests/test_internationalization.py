"""Internationalization tests for TOON format (Section 16 of spec).

Tests Unicode support, emoji handling, and UTF-8 encoding per
TOON specification Section 16 (Internationalization).
"""

import pytest

from toon_format import decode, encode


class TestUnicodeSupport:
    """Tests for full Unicode support in keys and values."""

    def test_emoji_in_string_values(self):
        """Emoji should be preserved in string values."""
        data = {"message": "Hello ğŸ‘‹ World ğŸŒ"}

        result = encode(data)
        assert "ğŸ‘‹" in result
        assert "ğŸŒ" in result

        decoded = decode(result)
        assert decoded["message"] == "Hello ğŸ‘‹ World ğŸŒ"

    def test_emoji_in_array_values(self):
        """Emoji should work in array elements."""
        data = {"tags": ["ğŸ‰", "ğŸŠ", "ğŸˆ"]}

        result = encode(data)
        assert "ğŸ‰" in result

        decoded = decode(result)
        assert decoded["tags"] == ["ğŸ‰", "ğŸŠ", "ğŸˆ"]

    def test_emoji_in_object_keys(self):
        """Emoji should work in object keys (when quoted)."""
        # Emoji keys need to be quoted per spec (not matching identifier pattern)
        data = {"status": "ğŸ‘"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["status"] == "ğŸ‘"

    def test_chinese_characters(self):
        """Chinese characters should be preserved."""
        data = {"greeting": "ä½ å¥½ä¸–ç•Œ", "items": ["è‹¹æœ", "é¦™è•‰", "æ©™å­"]}

        result = encode(data)
        assert "ä½ å¥½ä¸–ç•Œ" in result

        decoded = decode(result)
        assert decoded["greeting"] == "ä½ å¥½ä¸–ç•Œ"
        assert decoded["items"] == ["è‹¹æœ", "é¦™è•‰", "æ©™å­"]

    def test_arabic_characters(self):
        """Arabic characters should be preserved."""
        data = {"greeting": "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…", "numbers": ["ÙˆØ§Ø­Ø¯", "Ø§Ø«Ù†Ø§Ù†", "Ø«Ù„Ø§Ø«Ø©"]}

        result = encode(data)
        assert "Ù…Ø±Ø­Ø¨Ø§" in result

        decoded = decode(result)
        assert decoded["greeting"] == "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…"
        assert decoded["numbers"] == ["ÙˆØ§Ø­Ø¯", "Ø§Ø«Ù†Ø§Ù†", "Ø«Ù„Ø§Ø«Ø©"]

    def test_japanese_characters(self):
        """Japanese characters (Hiragana, Katakana, Kanji) should be preserved."""
        data = {"hiragana": "ã“ã‚“ã«ã¡ã¯", "katakana": "ã‚«ã‚¿ã‚«ãƒŠ", "kanji": "æ¼¢å­—"}

        result = encode(data)
        assert "ã“ã‚“ã«ã¡ã¯" in result
        assert "ã‚«ã‚¿ã‚«ãƒŠ" in result
        assert "æ¼¢å­—" in result

        decoded = decode(result)
        assert decoded["hiragana"] == "ã“ã‚“ã«ã¡ã¯"
        assert decoded["katakana"] == "ã‚«ã‚¿ã‚«ãƒŠ"
        assert decoded["kanji"] == "æ¼¢å­—"

    def test_korean_characters(self):
        """Korean characters (Hangul) should be preserved."""
        data = {"greeting": "ì•ˆë…•í•˜ì„¸ìš”"}

        result = encode(data)
        assert "ì•ˆë…•í•˜ì„¸ìš”" in result

        decoded = decode(result)
        assert decoded["greeting"] == "ì•ˆë…•í•˜ì„¸ìš”"

    def test_cyrillic_characters(self):
        """Cyrillic characters should be preserved."""
        data = {"greeting": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€", "items": ["ĞœĞ¾ÑĞºĞ²Ğ°", "Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³"]}

        result = encode(data)
        assert "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚" in result

        decoded = decode(result)
        assert decoded["greeting"] == "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€"
        assert decoded["items"] == ["ĞœĞ¾ÑĞºĞ²Ğ°", "Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³"]

    def test_mixed_scripts(self):
        """Mixed scripts in the same document should work."""
        data = {"english": "Hello", "chinese": "ä½ å¥½", "arabic": "Ù…Ø±Ø­Ø¨Ø§", "emoji": "ğŸ‘‹"}

        result = encode(data)
        decoded = decode(result)

        assert decoded["english"] == "Hello"
        assert decoded["chinese"] == "ä½ å¥½"
        assert decoded["arabic"] == "Ù…Ø±Ø­Ø¨Ø§"
        assert decoded["emoji"] == "ğŸ‘‹"


class TestUTF8Encoding:
    """Tests for UTF-8 encoding compliance."""

    def test_utf8_roundtrip(self):
        """UTF-8 strings should roundtrip correctly."""
        # Various Unicode characters
        data = {
            "ascii": "Hello",
            "latin": "CafÃ©",
            "symbols": "Â©Â®â„¢",
            "math": "âˆ‘âˆ«âˆ‚",
            "arrows": "â†â†’â†‘â†“",
            "emoji": "ğŸ˜€ğŸ˜ƒğŸ˜„",
        }

        result = encode(data)
        # Result should be UTF-8 encodable
        utf8_bytes = result.encode("utf-8")
        assert isinstance(utf8_bytes, bytes)

        # Should decode back correctly
        decoded = decode(result)
        assert decoded == data

    def test_bmp_characters(self):
        """Basic Multilingual Plane characters should work."""
        # Characters in BMP (U+0000 to U+FFFF)
        data = {"text": "Hello\u00a9World\u2603"}  # Â© and â˜ƒ

        result = encode(data)
        decoded = decode(result)
        assert decoded["text"] == "HelloÂ©Worldâ˜ƒ"

    def test_supplementary_plane_characters(self):
        """Supplementary plane characters (above U+FFFF) should work."""
        # Mathematical Alphanumeric Symbols (U+1D400-U+1D7FF)
        # Emoji (U+1F300-U+1F9FF)
        data = {"text": "ğ•³ğ–Šğ–‘ğ–‘ğ–” ğŸŒŸ"}  # Gothic letters and star emoji

        result = encode(data)
        decoded = decode(result)
        assert "ğ•³ğ–Šğ–‘ğ–‘ğ–”" in decoded["text"]
        assert "ğŸŒŸ" in decoded["text"]

    def test_zero_width_characters(self):
        """Zero-width characters should be preserved."""
        # Zero-width joiner and zero-width space
        data = {"text": "Hello\u200bWorld\u200d"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["text"] == "Hello\u200bWorld\u200d"

    def test_combining_characters(self):
        """Combining diacritical marks should be preserved."""
        # e with combining acute accent
        data = {"text": "e\u0301"}  # Ã© as e + combining acute

        result = encode(data)
        decoded = decode(result)
        assert decoded["text"] == "e\u0301"

    def test_rtl_text(self):
        """Right-to-left text should be preserved."""
        data = {"hebrew": "×©×œ×•×", "arabic": "Ù…Ø±Ø­Ø¨Ø§"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["hebrew"] == "×©×œ×•×"
        assert decoded["arabic"] == "Ù…Ø±Ø­Ø¨Ø§"


class TestSpecialUnicodeScenarios:
    """Tests for special Unicode scenarios."""

    def test_emoji_with_skin_tone_modifiers(self):
        """Emoji with skin tone modifiers should be preserved."""
        data = {"emoji": "ğŸ‘‹ğŸ»ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ½ğŸ‘‹ğŸ¾ğŸ‘‹ğŸ¿"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["emoji"] == "ğŸ‘‹ğŸ»ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ½ğŸ‘‹ğŸ¾ğŸ‘‹ğŸ¿"

    def test_emoji_with_zwj_sequences(self):
        """Emoji ZWJ sequences (family emojis etc) should be preserved."""
        # Family emoji composed with ZWJ
        data = {"family": "ğŸ‘¨\u200dğŸ‘©\u200dğŸ‘§\u200dğŸ‘¦"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["family"] == "ğŸ‘¨\u200dğŸ‘©\u200dğŸ‘§\u200dğŸ‘¦"

    def test_flag_emojis(self):
        """Flag emojis (regional indicator symbols) should be preserved."""
        # US flag: ğŸ‡ºğŸ‡¸ (U+1F1FA U+1F1F8)
        data = {"flags": "ğŸ‡ºğŸ‡¸ğŸ‡¬ğŸ‡§ğŸ‡¯ğŸ‡µ"}

        result = encode(data)
        decoded = decode(result)
        assert decoded["flags"] == "ğŸ‡ºğŸ‡¸ğŸ‡¬ğŸ‡§ğŸ‡¯ğŸ‡µ"

    def test_unicode_in_tabular_format(self):
        """Unicode should work in tabular array format."""
        data = {
            "users": [
                {"name": "Alice", "emoji": "ğŸ˜€"},
                {"name": "Bob", "emoji": "ğŸ˜ƒ"},
                {"name": "ææ˜", "emoji": "ğŸ˜„"},
            ]
        }

        result = encode(data)
        decoded = decode(result)
        assert decoded["users"][0]["emoji"] == "ğŸ˜€"
        assert decoded["users"][2]["name"] == "ææ˜"

    def test_unicode_with_internal_spaces(self):
        """Unicode with internal spaces should work unquoted."""
        data = {"text": "Hello ä¸–ç•Œ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚"}

        result = encode(data)
        # Internal spaces are safe unquoted per spec
        decoded = decode(result)
        assert decoded["text"] == "Hello ä¸–ç•Œ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚"

    def test_unicode_normalization_preserved(self):
        """Different Unicode normalizations should be preserved as-is."""
        # NFD vs NFC forms of Ã©
        nfc = {"text": "\u00e9"}  # Ã© as single character (NFC)
        nfd = {"text": "e\u0301"}  # Ã© as e + combining accent (NFD)

        result_nfc = encode(nfc)
        result_nfd = encode(nfd)

        decoded_nfc = decode(result_nfc)
        decoded_nfd = decode(result_nfd)

        # Should preserve the original normalization form
        assert decoded_nfc["text"] == "\u00e9"
        assert decoded_nfd["text"] == "e\u0301"
        # These are visually the same but different Unicode representations
        assert decoded_nfc["text"] != decoded_nfd["text"]


class TestLocaleIndependence:
    """Tests that TOON is locale-independent per Section 16."""

    def test_numbers_not_locale_formatted(self):
        """Numbers should not use locale-specific formatting."""
        data = {"value": 1000000.5}

        result = encode(data)
        # Should not have thousands separators or locale-specific decimal
        assert "1000000.5" in result or "1000000" in result
        # Should not have comma thousand separators
        assert "1,000,000" not in result
        # Should not have locale-specific decimal separator
        assert "1000000,5" not in result

        decoded = decode(result)
        assert decoded["value"] == 1000000.5

    def test_booleans_not_locale_formatted(self):
        """Booleans should always be true/false, not locale variants."""
        data = {"flag": True}

        result = encode(data)
        # Should be lowercase "true", not "True" or locale variants
        assert "flag: true" in result
        assert "True" not in result
        assert "TRUE" not in result

        decoded = decode(result)
        assert decoded["flag"] is True

    def test_null_not_locale_formatted(self):
        """Null should always be "null", not locale variants."""
        data = {"value": None}

        result = encode(data)
        # Should be lowercase "null"
        assert "value: null" in result
        assert "None" not in result
        assert "NULL" not in result

        decoded = decode(result)
        assert decoded["value"] is None
